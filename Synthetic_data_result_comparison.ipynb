{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from sdv.tabular import CTGAN, GaussianCopula, TVAE\n",
    "from sdv.evaluation import evaluate\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, matthews_corrcoef, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/binned_train.csv')\n",
    "test = pd.read_csv('../data/binned_test.csv')\n",
    "\n",
    "x_test = test.drop('G3', axis=1)\n",
    "y_test = test['G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high       313\n",
       "upper       98\n",
       "passing     63\n",
       "fail        12\n",
       "Name: G3, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['G3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "copulas = {'fail': GaussianCopula(),\n",
    "           'passing': GaussianCopula(),\n",
    "           'high': GaussianCopula(),\n",
    "           'upper': GaussianCopula()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticTrainingSet():\n",
    "    def __init__(self, data=None, target_label=None, classes=None, random_state=1, up_sample=0, synthetic_only=False, model='gaussian_copula'):\n",
    "        self.data = data.copy()\n",
    "        self.target_label = target_label\n",
    "        self.classes = classes\n",
    "        self.random_state = random_state\n",
    "        self.up_sample = up_sample\n",
    "        self.synthetic_only = synthetic_only\n",
    "        self._synthetic_data = dict()\n",
    "        self.models = dict()\n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        fit does not conform to the standard scikit-learn api call.\n",
    "        Instead, it is called as a stand alone post-initiation to create a set of pandas dataframes that can be used for other learning\n",
    "        \"\"\"\n",
    "        for _class in self.classes:\n",
    "            self.models[_class] = GaussianCopula()\n",
    "        self.class_data = {_class:self.data.loc[self.data[self.target_label] == _class] for _class in self.classes}\n",
    "        \n",
    "        up_sample = self.data[self.target_label].value_counts()\n",
    "        self._up_sample = up_sample.max() - up_sample + self.up_sample\n",
    "        \n",
    "        self.X = self.data.drop(self.target_label, axis=1)\n",
    "        self.y = self.data[self.target_label]\n",
    "        \n",
    "        self.sample_data()\n",
    "        \n",
    "        if self.synthetic_only:\n",
    "            self.df = self.synthetic_df\n",
    "        else:\n",
    "            self.df = pd.concat([self.data, self.synthetic_df])\n",
    " \n",
    "    \n",
    "    def sample_data(self):\n",
    "        \"\"\"\n",
    "        sample_data is called to construct the internal self.synthetic_df variable for repeated access in the class\n",
    "        \"\"\"\n",
    "        self.synthetic_df = list()\n",
    "        for _class, _model in self.models.items():\n",
    "            class_data = self.data[self.data[self.target_label] == _class]\n",
    "            _model.fit(class_data)\n",
    "            _sample_size = self._up_sample.loc[_class]\n",
    "            print(_sample_size)\n",
    "            if _sample_size > 0:\n",
    "                synth_data = self.sample_copulas(_model, _sample_size, self.random_state)\n",
    "                self._synthetic_data[_class] = synth_data\n",
    "                self.synthetic_df.append(synth_data)\n",
    "            else:\n",
    "                self._synthetic_data[_class] = pd.DataFrame(columns = self.data.columns)\n",
    "                \n",
    "        self.synthetic_df = pd.concat(self.synthetic_df)\n",
    "\n",
    "    def resample_data(self, sample_size, balance_data):\n",
    "        \"\"\"\n",
    "        Allows resampling of the models after they've already been fitted and set to the same random state\n",
    "        sample_size: how many samples to generage\n",
    "        balance_data: whether or not to create a balanced dataset with the original data added in\n",
    "        \"\"\"\n",
    "        resample_df = list()\n",
    "        if balance_data:\n",
    "            resample = self.data[self.target_label].value_counts()\n",
    "            resample = resample.max() - resample + sample_size\n",
    "        else:\n",
    "            resample = pd.Series([sample_size] * len(self.classes), index=self.classes)\n",
    "            \n",
    "        for _class, _model in self.models.items():\n",
    "            resample_size = resample.loc[_class]\n",
    "            if resample_size > 0:\n",
    "                synth_data = self.sample_copulas(_model, resample_size, self.random_state)\n",
    "                resample_df.append(synth_data)\n",
    "        \n",
    "        if balance_data:\n",
    "            resample_df.append(self.data)\n",
    "        resample_df = pd.concat(resample_df)\n",
    "        return resample_df\n",
    "        \n",
    "    \n",
    "    def sample_copulas(self, _model, sample_size, random_state, offset_sample=0):\n",
    "        \"\"\"\n",
    "        Sample from a dataset, original or synthetic, to produce a fixed data size\n",
    "        sample_size: The desired output when combined with any prior data\n",
    "        random_state: Seed value to set the random state\n",
    "        offset_sample: The offset provided to adjust to any existing data\n",
    "        \"\"\"\n",
    "        if offset_sample == sample_size:\n",
    "            return pd.DataFrame(columns=sample.columns)\n",
    "        _to_sample = sample_size - offset_sample\n",
    "        print(_to_sample)\n",
    "        np.random.seed(random_state)\n",
    "        return _model.sample(_to_sample)\n",
    "    \n",
    "    def split_synthetic_into_train(self, _data, target_label):\n",
    "        \"\"\"\n",
    "        _data: data with both X and y in it\n",
    "        target_label: the label to separate X from y for training\n",
    "        \"\"\"\n",
    "        return self.X, self.y\n",
    "\n",
    "        \n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        evaluate calls the existing evaluate() function from Synthetic Data Vault and returns the verbose results from it rather than an aggregate score\n",
    "        \"\"\"\n",
    "        for _class in self.classes:\n",
    "            class_data = self.data.loc[ self.data[self.target_label] == _class]\n",
    "            synthetic_data = self._synthetic_data[_class]\n",
    "            report = evaluate(synthetic_data, class_data, aggregate=False).round(3)\n",
    "            print(f'{_class}\\n{report}\\n---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SyntheticTrainingSet(train, 'G3', ['upper','passing','fail','high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "215\n",
      "250\n",
      "250\n",
      "301\n",
      "301\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = trainer.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1215\n",
      "1250\n",
      "1301\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "over_sampled = trainer.resample_data(1000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313\n",
      "1313\n",
      "1313\n",
      "1313\n"
     ]
    }
   ],
   "source": [
    "synthetic_only = trainer.resample_data(1313, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4215\n",
      "4250\n",
      "4301\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "large_oversampled = trainer.resample_data(4000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4313\n",
      "4313\n",
      "4313\n",
      "4313\n"
     ]
    }
   ],
   "source": [
    "large_synthetic = trainer.resample_data(4313, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[50,100,150,200,250,300,350,400],\n",
    "          'max_depth':[None],\n",
    "          'random_state':[42],\n",
    "          'class_weight':['balanced','balanced_subsample', None],\n",
    "          'max_features':['auto','sqrt','log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_etc = ExtraTreesClassifier()\n",
    "balanced_etc = ExtraTreesClassifier()\n",
    "oversampled_etc = ExtraTreesClassifier()\n",
    "synthetic_etc = ExtraTreesClassifier()\n",
    "large_oversampled_etc = ExtraTreesClassifier()\n",
    "large_synthetic_etc = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_clf = GridSearchCV(original_etc, params, n_jobs=-1, verbose=4, scoring='f1_weighted')\n",
    "balanced_clf = GridSearchCV(balanced_etc, params, n_jobs=-1, verbose=4, scoring='f1_weighted')\n",
    "oversampled_clf = GridSearchCV(oversampled_etc, params, n_jobs=-1, verbose=4, scoring='f1_weighted')\n",
    "synthetic_clf = GridSearchCV(synthetic_etc, params, n_jobs=-1, verbose=4, scoring='f1_weighted')\n",
    "large_oversampled_clf = GridSearchCV(large_oversampled_etc, params, n_jobs=-1, verbose=4, scoring='f1_weighted')\n",
    "large_synthetic_clf = GridSearchCV(large_synthetic_etc, params, n_jobs=-1, verbose=4, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'balanced_subsample',\n",
       "                                          None],\n",
       "                         'max_depth': [None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400],\n",
       "                         'random_state': [42]},\n",
       "             scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_clf.fit(train.drop('G3', axis=1), train['G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'balanced_subsample',\n",
       "                                          None],\n",
       "                         'max_depth': [None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400],\n",
       "                         'random_state': [42]},\n",
       "             scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_clf.fit(balanced_df.drop('G3', axis=1), balanced_df['G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'balanced_subsample',\n",
       "                                          None],\n",
       "                         'max_depth': [None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400],\n",
       "                         'random_state': [42]},\n",
       "             scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_clf.fit(over_sampled.drop('G3', axis=1), over_sampled['G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'balanced_subsample',\n",
       "                                          None],\n",
       "                         'max_depth': [None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400],\n",
       "                         'random_state': [42]},\n",
       "             scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_clf.fit(synthetic_only.drop('G3', axis=1), synthetic_only['G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'balanced_subsample',\n",
       "                                          None],\n",
       "                         'max_depth': [None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400],\n",
       "                         'random_state': [42]},\n",
       "             scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_oversampled_clf.fit(large_oversampled.drop('G3', axis=1), large_oversampled['G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'balanced_subsample',\n",
       "                                          None],\n",
       "                         'max_depth': [None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400],\n",
       "                         'random_state': [42]},\n",
       "             scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_synthetic_clf.fit(large_synthetic.drop('G3', axis=1), large_synthetic['G3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original\n",
    "0.1547459945488794\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.00      0.00      0.00         4\n",
    "        high       0.67      0.93      0.78       105\n",
    "     passing       0.29      0.10      0.14        21\n",
    "       upper       0.50      0.15      0.23        33\n",
    "\n",
    "    accuracy                           0.64       163\n",
    "   macro avg       0.36      0.30      0.29       163\n",
    "weighted avg       0.57      0.64      0.57       163\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "Combined Data Based on Full Data Set\n",
    "\n",
    "-----------------------------------\n",
    "original\n",
    "0.5298076142632129\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.00      0.00      0.00         4\n",
    "        high       0.76      0.98      0.85       105\n",
    "     passing       0.64      0.33      0.44        21\n",
    "       upper       1.00      0.48      0.65        33\n",
    "\n",
    "    accuracy                           0.77       163\n",
    "   macro avg       0.60      0.45      0.49       163\n",
    "weighted avg       0.77      0.77      0.74       163\n",
    "\n",
    "-----------------------------------\n",
    "large\n",
    "0.4555326806930739\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.00      0.00      0.00         4\n",
    "        high       0.73      0.99      0.84       105\n",
    "     passing       0.62      0.24      0.34        21\n",
    "       upper       1.00      0.36      0.53        33\n",
    "\n",
    "    accuracy                           0.74       163\n",
    "   macro avg       0.59      0.40      0.43       163\n",
    "weighted avg       0.75      0.74      0.69       163\n",
    "\n",
    "-----------------------------------\n",
    "very_large\n",
    "0.34866945512163566\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.00      0.00      0.00         4\n",
    "        high       0.70      0.98      0.81       105\n",
    "     passing       0.67      0.19      0.30        21\n",
    "       upper       0.89      0.24      0.38        33\n",
    "\n",
    "    accuracy                           0.71       163\n",
    "   macro avg       0.56      0.35      0.37       163\n",
    "weighted avg       0.71      0.71      0.64       163\n",
    "\n",
    "-----------------------------------\n",
    "extra_large\n",
    "0.3388472987253949\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.00      0.00      0.00         4\n",
    "        high       0.69      1.00      0.81       105\n",
    "     passing       0.75      0.14      0.24        21\n",
    "       upper       1.00      0.18      0.31        33\n",
    "\n",
    "    accuracy                           0.70       163\n",
    "   macro avg       0.61      0.33      0.34       163\n",
    "weighted avg       0.74      0.70      0.62       163\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "balanced with large resampling\n",
    "\n",
    "-----------------------------------\n",
    "0.4891806574022487\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.12      0.25      0.17         4\n",
    "        high       0.79      0.84      0.81       105\n",
    "     passing       0.47      0.43      0.45        21\n",
    "       upper       0.88      0.67      0.76        33\n",
    "\n",
    "    accuracy                           0.74       163\n",
    "   macro avg       0.57      0.55      0.55       163\n",
    "weighted avg       0.75      0.74      0.74       163\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "Class Specific Sampling\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "original\n",
    "0.1547459945488794\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.00      0.00      0.00         4\n",
    "        high       0.67      0.93      0.78       105\n",
    "     passing       0.29      0.10      0.14        21\n",
    "       upper       0.50      0.15      0.23        33\n",
    "\n",
    "    accuracy                           0.64       163\n",
    "   macro avg       0.36      0.30      0.29       163\n",
    "weighted avg       0.57      0.64      0.57       163\n",
    "\n",
    "-----------------------------------\n",
    "balanced\n",
    "0.2777622216346843\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       1.00      0.50      0.67         4\n",
    "        high       0.71      0.71      0.71       105\n",
    "     passing       0.44      0.52      0.48        21\n",
    "       upper       0.42      0.39      0.41        33\n",
    "\n",
    "    accuracy                           0.62       163\n",
    "   macro avg       0.64      0.53      0.57       163\n",
    "weighted avg       0.63      0.62      0.62       163\n",
    "\n",
    "-----------------------------------\n",
    "oversampled\n",
    "0.29021646897293163\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.67      0.50      0.57         4\n",
    "        high       0.73      0.67      0.70       105\n",
    "     passing       0.52      0.62      0.57        21\n",
    "       upper       0.36      0.42      0.39        33\n",
    "\n",
    "    accuracy                           0.61       163\n",
    "   macro avg       0.57      0.55      0.56       163\n",
    "weighted avg       0.63      0.61      0.61       163\n",
    "\n",
    "-----------------------------------\n",
    "large_oversampled\n",
    "0.31025806701850306\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.67      0.50      0.57         4\n",
    "        high       0.76      0.59      0.66       105\n",
    "     passing       0.33      0.62      0.43        21\n",
    "       upper       0.46      0.55      0.50        33\n",
    "\n",
    "    accuracy                           0.58       163\n",
    "   macro avg       0.55      0.56      0.54       163\n",
    "weighted avg       0.64      0.58      0.60       163\n",
    "\n",
    "-----------------------------------\n",
    "synthetic\n",
    "0.23533468901341467\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.75      0.75      0.75         4\n",
    "        high       0.75      0.47      0.58       105\n",
    "     passing       0.25      0.62      0.36        21\n",
    "       upper       0.36      0.45      0.40        33\n",
    "\n",
    "    accuracy                           0.49       163\n",
    "   macro avg       0.53      0.57      0.52       163\n",
    "weighted avg       0.61      0.49      0.52       163\n",
    "\n",
    "-----------------------------------\n",
    "large_synthetic\n",
    "0.20655751873176692\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fail       0.67      0.50      0.57         4\n",
    "        high       0.73      0.43      0.54       105\n",
    "     passing       0.25      0.62      0.35        21\n",
    "       upper       0.36      0.48      0.41        33\n",
    "\n",
    "    accuracy                           0.47       163\n",
    "   macro avg       0.50      0.51      0.47       163\n",
    "weighted avg       0.59      0.47      0.49       163\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "0.1547459945488794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.00      0.00      0.00         4\n",
      "        high       0.67      0.93      0.78       105\n",
      "     passing       0.29      0.10      0.14        21\n",
      "       upper       0.50      0.15      0.23        33\n",
      "\n",
      "    accuracy                           0.64       163\n",
      "   macro avg       0.36      0.30      0.29       163\n",
      "weighted avg       0.57      0.64      0.57       163\n",
      "\n",
      "-----------------------------------\n",
      "balanced\n",
      "0.2777622216346843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       1.00      0.50      0.67         4\n",
      "        high       0.71      0.71      0.71       105\n",
      "     passing       0.44      0.52      0.48        21\n",
      "       upper       0.42      0.39      0.41        33\n",
      "\n",
      "    accuracy                           0.62       163\n",
      "   macro avg       0.64      0.53      0.57       163\n",
      "weighted avg       0.63      0.62      0.62       163\n",
      "\n",
      "-----------------------------------\n",
      "oversampled\n",
      "0.29021646897293163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.67      0.50      0.57         4\n",
      "        high       0.73      0.67      0.70       105\n",
      "     passing       0.52      0.62      0.57        21\n",
      "       upper       0.36      0.42      0.39        33\n",
      "\n",
      "    accuracy                           0.61       163\n",
      "   macro avg       0.57      0.55      0.56       163\n",
      "weighted avg       0.63      0.61      0.61       163\n",
      "\n",
      "-----------------------------------\n",
      "large_oversampled\n",
      "0.31025806701850306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.67      0.50      0.57         4\n",
      "        high       0.76      0.59      0.66       105\n",
      "     passing       0.33      0.62      0.43        21\n",
      "       upper       0.46      0.55      0.50        33\n",
      "\n",
      "    accuracy                           0.58       163\n",
      "   macro avg       0.55      0.56      0.54       163\n",
      "weighted avg       0.64      0.58      0.60       163\n",
      "\n",
      "-----------------------------------\n",
      "synthetic\n",
      "0.23533468901341467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.75      0.75      0.75         4\n",
      "        high       0.75      0.47      0.58       105\n",
      "     passing       0.25      0.62      0.36        21\n",
      "       upper       0.36      0.45      0.40        33\n",
      "\n",
      "    accuracy                           0.49       163\n",
      "   macro avg       0.53      0.57      0.52       163\n",
      "weighted avg       0.61      0.49      0.52       163\n",
      "\n",
      "-----------------------------------\n",
      "large_synthetic\n",
      "0.20655751873176692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.67      0.50      0.57         4\n",
      "        high       0.73      0.43      0.54       105\n",
      "     passing       0.25      0.62      0.35        21\n",
      "       upper       0.36      0.48      0.41        33\n",
      "\n",
      "    accuracy                           0.47       163\n",
      "   macro avg       0.50      0.51      0.47       163\n",
      "weighted avg       0.59      0.47      0.49       163\n",
      "\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _clf_name, _clf in zip(['original','balanced','oversampled','large_oversampled','synthetic','large_synthetic'],\n",
    "                           [original_clf, balanced_clf, oversampled_clf, large_oversampled_clf, synthetic_clf, large_synthetic_clf]):\n",
    "    print(_clf_name)\n",
    "    _preds = _clf.predict(x_test)\n",
    "    print(matthews_corrcoef(y_test, _preds))\n",
    "    print(classification_report(y_test, _preds))\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high       313\n",
       "upper       98\n",
       "passing     63\n",
       "fail        12\n",
       "Name: G3, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['G3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:synthetic]",
   "language": "python",
   "name": "conda-env-synthetic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
